{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7bc394a",
   "metadata": {},
   "source": [
    "### Data categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281707cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loding image metadata to find categories\n",
    "cat_path = \"/home/mor/annotations_trainval2017/annotations/\"\n",
    "fname = \"instances_train2017\"\n",
    "f = open(cat_path + fname +'.json', \"r\")\n",
    "data = json.loads(f.read())\n",
    "\n",
    "imid = data['annotations'][0]['image_id']\n",
    "imcat = data['annotations'][0]['category_id']\n",
    "data.keys()\n",
    "print([cat['name']  for cat in data['categories'] if cat['id'] == imcat])\n",
    "# catname = [cat['name'] if cat['id'] == imcat for cat in data['categories']]\n",
    "# data['categories'][0]\n",
    "imid\n",
    "\n",
    "im1= plt.imread(path+\"/train2017/train2017/000000\" + str(imid) +\".jpg\")\n",
    "plt.imshow(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d02818e",
   "metadata": {},
   "source": [
    "## Drafts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ce114",
   "metadata": {},
   "source": [
    "# Loading files & Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ecb31f",
   "metadata": {},
   "source": [
    "### beta signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00499409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading beta signals\n",
    "beta_name1 = 'betas_session01.hdf5'\n",
    "beta_name2 = 'betas_session02.hdf5'\n",
    "stim_data_path = '/nsd_stim_info_merged.pkl'\n",
    "path = '/home/mor/NDS_project/imported_data'\n",
    "sub_path = path + \"/sub\"\n",
    "\n",
    "beta_s1 = np.concatenate((h5py.File(sub_path +\"1/\"+ beta_name1, \"r\")[\"betas\"], h5py.File(sub_path +\"1/\"+ beta_name2, \"r\")[\"betas\"]), axis=0)\n",
    "print(\"the size of the beta is: \" + str(beta_s1.shape) + \" the dimensions are: trial * Voxel X * Voxel Y * Voxel Z\")\n",
    "\n",
    "# beta_s2 = np.concatenate((h5py.File(sub_path +\"2/\"+ beta_name1, \"r\")[\"betas\"], h5py.File(sub_path +\"2/\"+ beta_name2, \"r\")[\"betas\"]), axis=0)\n",
    "# print(\"the size of the beta is: \" + str(beta_s2.shape) + \" the dimensions are: trial * Voxel X * Voxel Y * Voxel Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc39c5",
   "metadata": {},
   "source": [
    "### images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a347ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading images data\n",
    "\n",
    "def import_sub_stim_data(path:str, subnums:list, stim_data:str):\n",
    "    \"\"\"\n",
    "    This function takes the stimulation meta data, which states which subject got which stim and when, and return a\n",
    "    table with the meta data of the stims of the selected subject got, out of the first 1500 stimulations.\n",
    "    \n",
    "    path: str represent the project's files path\n",
    "    subnums: a list of subject nums, so we filter only rows of stimulation that all the defined subject were experienced\n",
    "    stim_data: stimulation data file name\n",
    "    \"\"\"\n",
    "    stiminf = pd.read_pickle(path + stim_data)\n",
    "    for subnum in subnums:\n",
    "        snum = str(subnum)    \n",
    "        stiminf = stiminf.loc[(stiminf['subject' + snum] == True) & (stiminf[\"subject\" + snum + \"_rep0\"] <= 1500)]\n",
    "    col_rep = [\"subject\" + str(snum) + \"_rep0\" for snum in subnums]\n",
    "    substims = stiminf.filter([\"cocoId\", \"cocoSplit\",\"cropBox\"] + col_rep).sort_values(by=\"subject\" + snum + \"_rep0\")\n",
    "    substims[\"zeronum\"] =   (12 - substims['cocoId'].fillna('').astype(str).str.len())\n",
    "    substims[\"path\"] = (substims[\"cocoSplit\"] +\"/\" + substims[\"cocoSplit\"] + \"/\" + substims[\"zeronum\"].apply(lambda x: x * '0') + (substims[\"cocoId\"]).astype(str) + \".jpg\")\n",
    "    substims = substims.reset_index()\n",
    "    return substims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2463d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "substims = import_sub_stim_data(path, [1,2], stim_data_path)\n",
    "sub1stims = import_sub_stim_data(path, [1], stim_data_path)\n",
    "\n",
    "display(sub1stims)\n",
    "# type(stim_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afbd8c",
   "metadata": {},
   "source": [
    "Here we are extracting the Stimulus data in its pickle format. This structure contains all 8 subjects and al 73K pictures they were presented. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbac4e",
   "metadata": {},
   "source": [
    "We filter the first 1500 documented repetitions that subject 1 has underwent. the difference between the repetition number and the number of actual rows is because sum of the repitition did not contain a stimulus (to my understanding) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aacadb",
   "metadata": {},
   "source": [
    "We concatenete the string to create the correct file path of each presented picture so we can load it afterwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displying an example picture \n",
    "print(\"number of train pictures: \" + str(len(os.listdir(path + \"/train2017/train2017\"))))\n",
    "os.listdir(path)\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 6), sharex=True, sharey=True)\n",
    "for ax, im_idx in zip(axs.flat, [1,7,23,46,55,78,99,100]):\n",
    "    im1_sub1= plt.imread(path+\"/\"+sub1stims.loc[im_idx][\"path\"])\n",
    "    im1_sub1.shape\n",
    "    ax.imshow(im1_sub1)\n",
    "    im1_sub1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going over all imageset and cut it\n",
    "\n",
    "ims_cut_sizes = [1]*len(sub1stims)\n",
    "ims_cuts = [1]*len(sub1stims)\n",
    "\n",
    "for i in range(len(sub1stims)):\n",
    "    im_sub = plt.imread(path+\"/\"+sub1stims.loc[i][\"path\"])\n",
    "    ims_cuts[i] = cut_pic(im_sub, sub1stims.loc[i][\"cropBox\"])\n",
    "    ims_cut_sizes[i] = ims_cuts[i].shape\n",
    "print(\"Done cutting pics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366825e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI mappings extracting\n",
    "def get_roi_vox_data(roi_voxels_fname:str, roi_dict_fname:str) -> (dict, np.ndarray):\n",
    "    \"\"\"\n",
    "       This function converts the voxels-ROI and ROInum-ROIname files to np.ndarray and a dictionary for convinience.\n",
    "    \"\"\"\n",
    "    visROIS = nib.load(roi_voxels_fname)\n",
    "    unique, counts = np.unique(visROIS.get_fdata(), return_counts=True)\n",
    "    roi_count = dict(zip(unique, counts))\n",
    "    print(\"collecting data from: \" + re.search('sub\\d/ROIs/(.+?).nii.gz',roi_voxels_fname).group(1))\n",
    "    print (\"relevant voxels: \" + str(sum(value for key, value in roi_count.items() if key > 0)))\n",
    "    print (roi_count)\n",
    "    roi_legend = open(roi_dict_fname, \"r\")\n",
    "    roi_len = roi_legend.read()\n",
    "    reg_list = re.split('\\t +\\n|\\n', roi_len)[:-1]\n",
    "    reg_dict = {val[0]:val[2:] for val in reg_list}\n",
    "    reg_dict[-1] = \"unrelated\"\n",
    "    print(\"categories are: \" + str(reg_dict))\n",
    "    return {'mapping': np.transpose(visROIS.get_fdata(),(2,1,0)), 'legend': reg_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053e2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROI voxels extracting- function application\n",
    "sub1roi_path = \"/home/mor/NDS_project/imported_data/sub1/ROIs\"\n",
    "sub2roi_path = \"/home/mor/NDS_project/imported_data/sub2/ROIs\"\n",
    "\n",
    "roi_voxels_fnames_s1 = sorted(glob.glob(sub1roi_path +\"/*.nii.gz\"))\n",
    "roi_dict_fnames_s1 = sorted(glob.glob(sub1roi_path +\"/*.mgz.ctab\"))\n",
    "ROIs_1 = {re.search('1/ROIs/(.+?).nii.gz',vfname).group(1) : get_roi_vox_data(vfname, rfname) for vfname, rfname in zip(roi_voxels_fnames_s1, roi_dict_fnames_s1)}\n",
    "\n",
    "roi_voxels_fnames_s2 = sorted(glob.glob(sub2roi_path +\"/*.nii.gz\"))\n",
    "roi_dict_fnames_s2 = sorted(glob.glob(sub2roi_path +\"/*.mgz.ctab\"))\n",
    "ROIs_2 = {re.search('2/ROIs/(.+?).nii.gz',vfname).group(1) : get_roi_vox_data(vfname, rfname) for vfname, rfname in zip(roi_voxels_fnames_s2, roi_dict_fnames_s2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd572f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_dict_fnames_s2\n",
    "ROIs_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3ba2f",
   "metadata": {},
   "source": [
    "ROIs is a dictionaty where the key is the name of the collection of the ROI (eg. visual cortex) and the values are a 2 items dictionary:\n",
    "\n",
    "mapping- the array of all the voxels and the value of each voxel is its belonging ROI,\n",
    "\n",
    "legend- a dictionary of ROI number : ROI name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116c237",
   "metadata": {},
   "source": [
    "applying function get_roi_vox_data creates a dictionary of a size of the ROI files number we proccess, each element is of size two having the voxels data and the dictionaty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voxels_roi(collection, betas, pics_df, df_col):\n",
    "    \"\"\"\n",
    "    This function will return a matrix all the stimului * all the voxels of a certain ROI \n",
    "    inputs:\n",
    "        collection: list of two which is an object of the ROI dict output\n",
    "        betas: the betas signal\n",
    "    \"\"\"\n",
    "    voxels_ROIS = {}\n",
    "    ROI_num = len(collection['legend'].keys())\n",
    "    for i in range(1, ROI_num-1):\n",
    "        ROI_reg_name = collection['legend'][str(i)]\n",
    "        filterROI = (collection['mapping'] == i).astype(int)\n",
    "        betas_reg_roi = np.multiply(betas, np.expand_dims(filterROI, axis=0))\n",
    "        betas_reg_roi = betas_reg_roi.reshape((len(betas), np.prod(list(betas_reg_roi.shape[1:]))))\n",
    "        betas_reg_roi = betas_reg_roi[:,~np.all(betas_reg_roi == 0, axis=0)]\n",
    "        when_pics = list(pics_df[df_col]) # filtering out the beta reps when there was no pic presented\n",
    "        when_pics = [when-1  for when in when_pics if when <= len(betas)]\n",
    "        betas_reg_roi = betas_reg_roi[when_pics,:]\n",
    "        betas_reg_roi = zscore(betas_reg_roi)\n",
    "        voxels_ROIS[ROI_reg_name] = betas_reg_roi\n",
    "        print(\"extracting voxels for: \" + ROI_reg_name)\n",
    "    return voxels_ROIS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aa22145",
   "metadata": {},
   "source": [
    "# ROIs for subject comparisons\n",
    "voxels_ROIs_s1 = {key : get_voxels_roi(ROIs_1[key], beta_s1, substims, 'subject1_rep0') for key in ROIs_1.keys()}\n",
    "voxels_ROIs_s2 = {key : get_voxels_roi(ROIs_2[key], beta_s2, substims, 'subject2_rep0') for key in ROIs_2.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROIs for sub1\n",
    "# voxels_ROIs_full1 = {key : get_voxels_roi(ROIs_1[key], beta_s1, sub1stims, 'subject1_rep0') for key in ROIs_1.keys()}\n",
    "\n",
    "with open ('/home/mor/NDS_project/imported_datavoxels_ROIs.pkl', 'rb') as f:\n",
    "    voxels_ROIs_full1 = pkl.load(f)\n",
    "RDM_fmri_s1 = {}\n",
    "for area in voxels_ROIs_full.keys():\n",
    "    RDM_fmri_s1[area] = {}\n",
    "    for roi in voxels_ROIs_full[area].keys():\n",
    "        RDM_fmri_s1[area][roi] = 1-np.corrcoef(voxels_ROIs_full[area][roi][:net_lim,:])\n",
    "    print(\"Created RDM for: \" + str(area))\n",
    "RDM_fmri_s1['prf-visualrois']['V1v'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a835daf",
   "metadata": {},
   "source": [
    "## Image filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc96e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pictures cutting\n",
    "def cut_pic(im, cutbox):\n",
    "    \"\"\"\n",
    "    This function gets the original image, and cuts it according to the matching cropBox given by the metadata table.\n",
    "    the crop box used to cut the pictures to present them to the subject in the fMRI experiment \n",
    "    \"\"\"\n",
    "    im_len = im.shape[0]\n",
    "    im_wid = im.shape[1]\n",
    "    cut_im = np.ones(im.shape)*128\n",
    "    cut_im = im[int(im_len*cutbox[0]):int(im_len*(1-cutbox[1])), int(im_wid*cutbox[2]):int(im_wid*(1-cutbox[3])),:]\n",
    "    return cut_im.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3df2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e805d3",
   "metadata": {},
   "source": [
    "## two subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fde70",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDM_fmri_s1 = {}\n",
    "for area in voxels_ROIs_full.keys():\n",
    "    RDM_fmri_s1[area] = {}\n",
    "    for roi in voxels_ROIs_full[area].keys():\n",
    "        RDM_fmri_s1[area][roi] = 1-np.corrcoef(voxels_ROIs_full[area][roi][:net_lim,:])\n",
    "    print(\"Created RDM for: \" + str(area))\n",
    "    \n",
    "# RDM_fmri_s2 = {}\n",
    "# for area in voxels_ROIs_s2.keys():\n",
    "#     RDM_fmri_s2[area] = {}\n",
    "#     for roi in voxels_ROIs_s2[area].keys():\n",
    "#         RDM_fmri_s2[area][roi] = 1-np.corrcoef(voxels_ROIs_s2[area][roi][:net_lim,:])\n",
    "#     print(\"Created RDM for: \" + str(area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying for sub2\n",
    "net_size = 224\n",
    "batch_size = 64\n",
    "path = '/home/mor/NDS_project/imported_data'\n",
    "stim_data_path = '/nsd_stim_info_merged.pkl'\n",
    "sub_path = path + \"/sub\"\n",
    "\n",
    "with open ('/home/mor/NDS_project/imported_data/sub2/beta_s2.pkl', 'rb') as f:\n",
    "    beta_s2 = pkl.load(f)\n",
    "print(\"the size of the beta is: \" + str(beta_s2.shape) + \" the dimensions are: trial * Voxel X * Voxel Y * Voxel Z\")\n",
    "sub2stims = import_sub_stim_data(path, [2], stim_data_path)\n",
    "net_lim = (len(sub2stims) // batch_size) * batch_size\n",
    "\n",
    "#ROIs for sub2\n",
    "# If saved:\n",
    "with open ('/home/mor/NDS_project/imported_data/sub2/voxels_ROIs_full2.pkl', 'rb') as f:\n",
    "    voxels_ROIs_full2 = pkl.load(f)\n",
    "    \n",
    "RDM_fmri_2 = {}\n",
    "for area in voxels_ROIs_full2.keys():\n",
    "    RDM_fmri_2[area] = {}\n",
    "    for roi in voxels_ROIs_full2[area].keys():\n",
    "        RDM_fmri_2[area][roi] = 1-np.corrcoef(voxels_ROIs_full2[area][roi][:net_lim,:])\n",
    "    print(\"Created RDM for: \" + str(area))\n",
    "\n",
    "    \n",
    "# Going over all imageset and cut it\n",
    "ims_cuts = [1]*len(sub2stims)\n",
    "\n",
    "for i in range(len(sub2stims)):\n",
    "    im_sub = plt.imread(path+\"/\" + sub2stims.loc[i][\"path\"])\n",
    "    ims_cuts[i] = cut_pic(im_sub, sub2stims.loc[i][\"cropBox\"])\n",
    "print(\"Done cutting pics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93caa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(visualrois_V1v[:,590])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd65ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to navigate pathes\n",
    "path = \"/home/mor\"\n",
    "print(glob.glob(path+ \"/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # working with ROIS - Draft\n",
    "# print(\"Importing ROI Data\")\n",
    "# visROIS = nib.load(sub1roi_path + \"/prf-visualrois.nii.gz\")\n",
    "# roi_legend = open(sub1roi_path +  '/prf-visualrois.mgz.ctab', \"r\")\n",
    "# roi_len = roi_legend.read()\n",
    "# unique, counts = np.unique(visROIS.get_fdata(), return_counts=True)\n",
    "# roi_count = dict(zip(unique, counts))\n",
    "# print (\"relevant voxels: \" + str(sum(value for key, value in roi_count.items() if key > 0)))\n",
    "# roi_count\n",
    "# visROIS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc755f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # working with an example ROI - Chose visualrois_V1v\n",
    "# # ROI_title = ROIs.keys(0) + ROIs[ROIs.keys(0)][1]\n",
    "# ROIs_names = list(ROIs.keys())\n",
    "# reg_ROI_num = 1\n",
    "# reg_ROI_name = ROIs_names[-1] + \"_\" + ROIs[ROIs_names[-1]][1][str(reg_ROI_num)]\n",
    "# filterROI = (ROIs[ROIs_names[-1]][0] == reg_ROI_num).astype(int)\n",
    "# visualrois_V1v = np.multiply(beta_s1, np.expand_dims(filterROI, axis=0))\n",
    "# reg_ROI_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(visualrois_V1v)\n",
    "# visualrois_V1v = visualrois_V1v.reshape((750, np.prod(list(visualrois_V1v.shape[1:]))))\n",
    "# visualrois_V1v = visualrois_V1v[:,~np.all(visualrois_V1v == 0, axis=0)]\n",
    "# when_pics = list(sub1stims['subject1_rep0']) # filtering out the beta reps when there was no pic presented\n",
    "# when_pics = [when-1  for when in when_pics if when <= 750]\n",
    "# visualrois_V1v = visualrois_V1v[when_pics,:]\n",
    "# visualrois_V1v = zscore(visualrois_V1v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bdd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = copy.deepcopy(roi_len)\n",
    "# reg_list = re.split('\\t +\\n|\\n', roi_len)[:-1]\n",
    "# reg_dict = {val[0]:val[2:] for val in reg_list}\n",
    "# reg_dict[-1] = \"unrelated\"\n",
    "# reg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input()\n",
    "print('Hello, ' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf9008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
